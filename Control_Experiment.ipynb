{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are data generation. Don't change. Training data are pairs of neighbor numbers. Validation data are pairs of random numbers.  \n",
    "The purpose of this setup is that if the model can generalize the relationship of the numbers from simple training data, then it is possible to do numerical reasoning whose training is on limited combination of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [idx for idx in range(0, 15000)] * 2 + [idx+1 for idx in range(0, 15000)]\n",
    "x2 = [idx for idx in range(0, 15000)] + [idx+1 for idx in range(0, 15000)] + [idx for idx in range(0, 15000)]\n",
    "x1, x2 = np.array(x1), np.array(x2)\n",
    "y = (x1 >= x2) * 1 + (x1 > x2) * 1\n",
    "train_data = [x1, x2, y]\n",
    "train_data = zip(*train_data)\n",
    "train_data = sorted(train_data, key=lambda x: x[0])\n",
    "train_data = list(zip(*train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.randint(0, 15000, 10000)\n",
    "x2 = np.random.randint(0, 15000, 10000)\n",
    "y = (x1 >= x2) * 1 + (x1 > x2) * 1\n",
    "val_data = [x1, x2, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "int_pair_list = list(itertools.permutations(list(range(300)), 2)) + [(i,i) for i in range(300)]*30\n",
    "random.shuffle(int_pair_list)\n",
    "x1 = [x[0] for x in int_pair_list]\n",
    "x2 = [x[1] for x in int_pair_list]\n",
    "x1, x2 = np.array(x1), np.array(x2)\n",
    "y = (x1 >= x2) * 1 + (x1 > x2) * 1\n",
    "train_data_JP = [x1[:70000], x2[:70000], y[:70000]]\n",
    "val_data_JP = [x1[70000:], x2[70000:], y[70000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [idx for idx in range(0, 150)] * 2 + [idx+1 for idx in range(0, 150)]\n",
    "x2 = [idx for idx in range(0, 150)] + [idx+1 for idx in range(0, 150)] + [idx for idx in range(0, 150)]\n",
    "x1, x2 = np.array(x1), np.array(x2)\n",
    "y = (x1 >= x2) * 1 + (x1 > x2) * 1\n",
    "train_data_short = [x1, x2, y]\n",
    "train_data_short = zip(*train_data_short)\n",
    "train_data_short = sorted(train_data_short, key=lambda x: x[0])\n",
    "train_data_short = list(zip(*train_data_short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BSZ = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the train and validate functions. Don't need to change unless want to try variations of training paradigm such as using multiclass SVM loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, train_loader, val_loader, fail_tol, learning_rate=3e-4, label=\"\"):\n",
    "\n",
    "    num_epochs = 1000\n",
    "\n",
    "#     criterion = torch.nn.MultiMarginLoss()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.LBFGS(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.1)\n",
    "    \n",
    "    def closure():\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, labels)\n",
    "            for param in model.parameters():\n",
    "                loss += 1e-3 * torch.norm(param)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "            return loss\n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    loss_list, val_acc_list = [], []\n",
    "    \n",
    "    fail_cnt, cur_best = 0, 0\n",
    "    for epoch in range(num_epochs+1):\n",
    "        \n",
    "        avg_loss = 0.\n",
    "        if epoch > 0:\n",
    "            for i, (x, labels) in enumerate(train_loader):\n",
    "                model.train()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(x)\n",
    "                    obj = criterion(outputs, labels)                \n",
    "                optimizer.step(closure)\n",
    "\n",
    "                avg_loss += obj.item() / len(train_loader)\n",
    "            \n",
    "        val_acc = test_model(val_loader, model)\n",
    "        train_acc = test_model(train_loader, model)\n",
    "        val_acc_list.append(val_acc)\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        if (val_acc > cur_best):\n",
    "            print('Epoch: [{}/{}], Loss: {:.4}, Train acc: {:.4}, Val acc: {:.4}'.format(\n",
    "                epoch, num_epochs, avg_loss, train_acc, val_acc))\n",
    "            print(\"found best! save model...\")\n",
    "            torch.save(model.state_dict(), 'model' + \"-\" + label + '.ckpt')\n",
    "            cur_best = val_acc\n",
    "            fail_cnt = 0\n",
    "        else:\n",
    "            fail_cnt += 1\n",
    "            print('Epoch: [{}/{}], Loss: {:.4}, Train acc: {:.4}, Val acc: {:.4} ({}/{})'.format(\n",
    "                epoch, num_epochs, avg_loss, train_acc, val_acc, fail_cnt, fail_tol))\n",
    "        if fail_cnt > fail_tol:\n",
    "            return loss_list, val_acc_list\n",
    "\n",
    "#         scheduler.step(val_acc)\n",
    "    return loss_list, val_acc_list\n",
    "\n",
    "def test_model(loader, model):\n",
    "    from collections import Counter\n",
    "    res_cnt = Counter()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for x, labels in loader:\n",
    "        outputs = model(x)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "#         labels = labels.max(1)[1]\n",
    "        res_cnt.update(list(predicted.squeeze().cpu().numpy()))\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    print(res_cnt)\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to input the pairs. Concatenation ($N\\times 2$) and subtraction ($N\\times 1$). Although subtraction should presumably be learned (with concatenation), it doesn't seem to work that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class numDataset(Dataset):\n",
    "    def __init__(self, data_list, device=DEVICE):\n",
    "        self.s1_list, self.s2_list, self.target_list = data_list\n",
    "        self.device = device\n",
    "        assert (len(self.s1_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "        \n",
    "    def __getitem__(self, key):    \n",
    "\n",
    "        s1_idx = self.s1_list[key]\n",
    "        s2_idx = self.s2_list[key]       \n",
    "        label = self.target_list[key]\n",
    "\n",
    "        return [s1_idx, s2_idx, label, self.device]\n",
    "    \n",
    "def collate_func(batch):\n",
    "    device = batch[0][3]\n",
    "    data_list, label_list = [], []\n",
    "    for datum in batch:\n",
    "        # Can change comma to minus (or minus to comma) in the next line\n",
    "        data_list.append([datum[0] , datum[1]])\n",
    "        label_list.append(datum[2])\n",
    "\n",
    "    return [torch.FloatTensor(np.array(data_list)).to(device), \n",
    "            torch.LongTensor(label_list).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = numDataset(train_data)\n",
    "val_dataset = numDataset(val_data)\n",
    "train_dataset_short = numDataset(train_data_short)\n",
    "train_dataset_JP = numDataset(train_data_JP)\n",
    "val_dataset_JP = numDataset(val_data_JP)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BSZ,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BSZ,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)\n",
    "train_loader_short = torch.utils.data.DataLoader(dataset=train_dataset_short,\n",
    "                                           batch_size=BSZ,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "train_loader_JP = torch.utils.data.DataLoader(dataset=train_dataset_JP,\n",
    "                                           batch_size=BSZ,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "val_loader_JP = torch.utils.data.DataLoader(dataset=val_dataset_JP,\n",
    "                                           batch_size=BSZ,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using subtraction, input is 1d. Concatenation is 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcNet(nn.Module):\n",
    "    def __init__(self, n_layers, fc_hid_dim, device=DEVICE):\n",
    "        super(fcNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.fc_hid_dim = fc_hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Specify the input dimension here\n",
    "        if n_layers == 1:\n",
    "            self.linears = nn.ModuleList([nn.Linear(2,3)])\n",
    "        else:\n",
    "            self.linears = nn.ModuleList([nn.Sequential(nn.Linear(2, fc_hid_dim), nn.Tanh())]+\n",
    "                                         [nn.Sequential(nn.Linear(fc_hid_dim, fc_hid_dim), nn.Tanh())] * (n_layers-2)+\n",
    "                                         [nn.Linear(fc_hid_dim, 3)])\n",
    "        self.init_weights()\n",
    "    def forward(self, x):\n",
    "        for linear in self.linears:\n",
    "            x = linear(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [layer if type(layer) == torch.nn.modules.linear.Linear else layer[0] for layer in self.linears]\n",
    "     \n",
    "        for layer in lin_layers:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "#             layer.weight.data.zero_()\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is here. Feel free to change the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcNet(\n",
      "  (linears): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (3): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Counter({2: 44995, 0: 5})\n",
      "Counter({2: 54040, 0: 11785, 1: 4175})\n",
      "Epoch: [0/1000], Loss: 0.0, Train acc: 35.08, Val acc: 33.32\n",
      "found best! save model...\n",
      "Counter({0: 44689, 2: 311})\n",
      "Counter({0: 37546, 2: 32454})\n",
      "Epoch: [1/1000], Loss: 0.7384, Train acc: 90.81, Val acc: 33.96\n",
      "found best! save model...\n",
      "Counter({2: 44275, 1: 645, 0: 80})\n",
      "Counter({2: 32593, 0: 31370, 1: 6037})\n",
      "Epoch: [2/1000], Loss: 0.212, Train acc: 98.54, Val acc: 34.13\n",
      "found best! save model...\n",
      "Counter({2: 41749, 1: 3242, 0: 9})\n",
      "Counter({2: 31676, 0: 31274, 1: 7050})\n",
      "Epoch: [3/1000], Loss: 0.1239, Train acc: 98.78, Val acc: 33.94 (1/66)\n",
      "Counter({2: 31931, 1: 13064, 0: 5})\n",
      "Counter({2: 31406, 0: 31301, 1: 7293})\n",
      "Epoch: [4/1000], Loss: 0.08487, Train acc: 98.76, Val acc: 35.08\n",
      "found best! save model...\n",
      "Counter({2: 35590, 1: 9407, 0: 3})\n",
      "Counter({2: 31481, 0: 31272, 1: 7247})\n",
      "Epoch: [5/1000], Loss: 0.06432, Train acc: 98.82, Val acc: 34.78 (1/66)\n",
      "Counter({1: 28796, 0: 16199, 2: 5})\n",
      "Counter({2: 31443, 0: 31391, 1: 7166})\n",
      "Epoch: [6/1000], Loss: 0.05219, Train acc: 98.94, Val acc: 58.31\n",
      "found best! save model...\n",
      "Counter({0: 43080, 1: 1916, 2: 4})\n",
      "Counter({0: 31464, 2: 31342, 1: 7194})\n",
      "Epoch: [7/1000], Loss: 0.0454, Train acc: 98.9, Val acc: 34.04 (1/66)\n",
      "Counter({2: 43904, 1: 1094, 0: 2})\n",
      "Counter({2: 31747, 0: 31201, 1: 7052})\n",
      "Epoch: [8/1000], Loss: 0.03943, Train acc: 99.1, Val acc: 33.73 (2/66)\n",
      "Counter({0: 43149, 1: 1846, 2: 5})\n",
      "Counter({0: 31513, 2: 31494, 1: 6993})\n",
      "Epoch: [9/1000], Loss: 0.03649, Train acc: 99.19, Val acc: 34.21 (3/66)\n",
      "Counter({0: 43319, 1: 1676, 2: 5})\n",
      "Counter({0: 31561, 2: 31490, 1: 6949})\n",
      "Epoch: [10/1000], Loss: 0.03192, Train acc: 99.25, Val acc: 34.23 (4/66)\n",
      "Counter({0: 43673, 1: 1322, 2: 5})\n",
      "Counter({0: 31578, 2: 31505, 1: 6917})\n",
      "Epoch: [11/1000], Loss: 0.02919, Train acc: 99.3, Val acc: 34.01 (5/66)\n",
      "Counter({2: 40664, 1: 4333, 0: 3})\n",
      "Counter({2: 31676, 0: 31465, 1: 6859})\n",
      "Epoch: [12/1000], Loss: 0.02792, Train acc: 99.38, Val acc: 35.39 (6/66)\n",
      "Counter({0: 36904, 1: 8089, 2: 7})\n",
      "Counter({2: 31615, 0: 31466, 1: 6919})\n",
      "Epoch: [13/1000], Loss: 0.02497, Train acc: 99.29, Val acc: 36.52 (7/66)\n",
      "Counter({2: 43086, 1: 1909, 0: 5})\n",
      "Counter({2: 31737, 0: 31437, 1: 6826})\n",
      "Epoch: [14/1000], Loss: 0.02261, Train acc: 99.43, Val acc: 34.32 (8/66)\n",
      "Counter({2: 33677, 1: 11317, 0: 6})\n",
      "Counter({2: 31676, 0: 31468, 1: 6856})\n",
      "Epoch: [15/1000], Loss: 0.02262, Train acc: 99.38, Val acc: 38.96 (9/66)\n",
      "Counter({2: 27608, 1: 17386, 0: 6})\n",
      "Counter({2: 31677, 0: 31468, 1: 6855})\n",
      "Epoch: [16/1000], Loss: 0.02223, Train acc: 99.38, Val acc: 38.76 (10/66)\n",
      "Counter({2: 43686, 1: 1307, 0: 7})\n",
      "Counter({2: 31816, 0: 31428, 1: 6756})\n",
      "Epoch: [17/1000], Loss: 0.01997, Train acc: 99.53, Val acc: 34.13 (11/66)\n",
      "Counter({0: 38331, 1: 6660, 2: 9})\n",
      "Counter({2: 31678, 0: 31476, 1: 6846})\n",
      "Epoch: [18/1000], Loss: 0.01702, Train acc: 99.4, Val acc: 38.01 (12/66)\n",
      "Counter({0: 40273, 1: 4715, 2: 12})\n",
      "Counter({2: 31680, 0: 31527, 1: 6793})\n",
      "Epoch: [19/1000], Loss: 0.02075, Train acc: 99.47, Val acc: 36.66 (13/66)\n",
      "Counter({0: 42454, 1: 2534, 2: 12})\n",
      "Counter({2: 31680, 0: 31656, 1: 6664})\n",
      "Epoch: [20/1000], Loss: 0.01621, Train acc: 99.66, Val acc: 35.12 (14/66)\n",
      "Counter({2: 42535, 1: 2451, 0: 14})\n",
      "Counter({2: 31888, 0: 31474, 1: 6638})\n",
      "Epoch: [21/1000], Loss: 0.01371, Train acc: 99.69, Val acc: 35.2 (15/66)\n",
      "Counter({2: 43545, 1: 1440, 0: 15})\n",
      "Counter({2: 31888, 0: 31475, 1: 6637})\n",
      "Epoch: [22/1000], Loss: 0.01478, Train acc: 99.7, Val acc: 34.44 (16/66)\n",
      "Counter({2: 40235, 1: 4683, 0: 82})\n",
      "Counter({2: 31888, 0: 31527, 1: 6585})\n",
      "Epoch: [23/1000], Loss: 0.01373, Train acc: 99.77, Val acc: 37.63 (17/66)\n",
      "Counter({2: 42447, 1: 2538, 0: 15})\n",
      "Counter({2: 31888, 0: 31475, 1: 6637})\n",
      "Epoch: [24/1000], Loss: 0.01161, Train acc: 99.7, Val acc: 35.38 (18/66)\n",
      "Counter({0: 44017, 1: 962, 2: 21})\n",
      "Counter({0: 31688, 2: 31662, 1: 6650})\n",
      "Epoch: [25/1000], Loss: 0.01084, Train acc: 99.68, Val acc: 34.07 (19/66)\n",
      "Counter({0: 27198, 1: 17719, 2: 83})\n",
      "Counter({2: 31733, 0: 31688, 1: 6579})\n",
      "Epoch: [26/1000], Loss: 0.01976, Train acc: 99.78, Val acc: 47.28 (20/66)\n",
      "Counter({2: 42823, 1: 2112, 0: 65})\n",
      "Counter({2: 31888, 0: 31515, 1: 6597})\n",
      "Epoch: [27/1000], Loss: 0.01093, Train acc: 99.75, Val acc: 35.25 (21/66)\n",
      "Counter({2: 39378, 1: 5390, 0: 232})\n",
      "Counter({2: 31888, 0: 31640, 1: 6472})\n",
      "Epoch: [28/1000], Loss: 0.01133, Train acc: 99.93, Val acc: 38.5 (22/66)\n",
      "Counter({0: 43620, 1: 1286, 2: 94})\n",
      "Counter({2: 31741, 0: 31688, 1: 6571})\n",
      "Epoch: [29/1000], Loss: 0.009022, Train acc: 99.79, Val acc: 34.51 (23/66)\n",
      "Counter({2: 41050, 1: 3735, 0: 215})\n",
      "Counter({2: 31888, 0: 31628, 1: 6484})\n",
      "Epoch: [30/1000], Loss: 0.01276, Train acc: 99.91, Val acc: 36.66 (24/66)\n",
      "Counter({2: 34622, 1: 10145, 0: 233})\n",
      "Counter({2: 31888, 0: 31641, 1: 6471})\n",
      "Epoch: [31/1000], Loss: 0.01078, Train acc: 99.93, Val acc: 41.65 (25/66)\n",
      "Counter({0: 44019, 1: 927, 2: 54})\n",
      "Counter({0: 32079, 2: 31713, 1: 6208})\n",
      "Epoch: [32/1000], Loss: 0.01185, Train acc: 99.19, Val acc: 34.08 (26/66)\n",
      "Counter({2: 37212, 1: 7170, 0: 618})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [33/1000], Loss: 0.009211, Train acc: 100.0, Val acc: 39.79 (27/66)\n",
      "Counter({2: 37736, 1: 6759, 0: 505})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [34/1000], Loss: 0.006015, Train acc: 100.0, Val acc: 40.36 (28/66)\n",
      "Counter({0: 43924, 1: 981, 2: 95})\n",
      "Counter({2: 31742, 0: 31688, 1: 6570})\n",
      "Epoch: [35/1000], Loss: 0.003611, Train acc: 99.79, Val acc: 34.26 (29/66)\n",
      "Counter({0: 34648, 1: 9961, 2: 391})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [36/1000], Loss: 0.004752, Train acc: 100.0, Val acc: 39.53 (30/66)\n",
      "Counter({0: 43861, 1: 1039, 2: 100})\n",
      "Counter({2: 31746, 0: 31688, 1: 6566})\n",
      "Epoch: [37/1000], Loss: 0.00337, Train acc: 99.8, Val acc: 34.29 (31/66)\n",
      "Counter({0: 43625, 1: 1241, 2: 134})\n",
      "Counter({2: 31775, 0: 31688, 1: 6537})\n",
      "Epoch: [38/1000], Loss: 0.004542, Train acc: 99.84, Val acc: 34.53 (32/66)\n",
      "Counter({2: 38873, 1: 5562, 0: 565})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [39/1000], Loss: 0.005478, Train acc: 100.0, Val acc: 39.24 (33/66)\n",
      "Counter({2: 35120, 1: 8941, 0: 939})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [40/1000], Loss: 0.003385, Train acc: 100.0, Val acc: 42.86 (34/66)\n",
      "Counter({1: 23557, 0: 21101, 2: 342})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [41/1000], Loss: 0.00174, Train acc: 100.0, Val acc: 53.87 (35/66)\n",
      "Counter({2: 42185, 1: 2502, 0: 313})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [42/1000], Loss: 0.002781, Train acc: 100.0, Val acc: 36.08 (36/66)\n",
      "Counter({0: 37568, 1: 6906, 2: 526})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [43/1000], Loss: 0.004322, Train acc: 100.0, Val acc: 38.77 (37/66)\n",
      "Counter({1: 20396, 0: 19910, 2: 4694})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [44/1000], Loss: 0.003216, Train acc: 100.0, Val acc: 66.19\n",
      "found best! save model...\n",
      "Counter({0: 41997, 1: 2858, 2: 145})\n",
      "Counter({2: 31780, 0: 31688, 1: 6532})\n",
      "Epoch: [45/1000], Loss: 0.002352, Train acc: 99.85, Val acc: 35.26 (1/66)\n",
      "Counter({1: 32980, 2: 10582, 0: 1438})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [46/1000], Loss: 0.001882, Train acc: 100.0, Val acc: 60.04 (2/66)\n",
      "Counter({2: 36800, 1: 7128, 0: 1072})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [47/1000], Loss: 0.002744, Train acc: 100.0, Val acc: 41.98 (3/66)\n",
      "Counter({2: 39407, 1: 4893, 0: 700})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [48/1000], Loss: 0.001924, Train acc: 100.0, Val acc: 38.86 (4/66)\n",
      "Counter({2: 42763, 1: 2013, 0: 224})\n",
      "Counter({2: 31888, 0: 31634, 1: 6478})\n",
      "Epoch: [49/1000], Loss: 0.001826, Train acc: 99.92, Val acc: 35.54 (5/66)\n",
      "Counter({2: 43751, 1: 1107, 0: 142})\n",
      "Counter({2: 31888, 0: 31572, 1: 6540})\n",
      "Epoch: [50/1000], Loss: 0.001803, Train acc: 99.83, Val acc: 34.56 (6/66)\n",
      "Counter({2: 41981, 1: 2725, 0: 294})\n",
      "Counter({2: 31888, 0: 31685, 1: 6427})\n",
      "Epoch: [51/1000], Loss: 0.003629, Train acc: 100.0, Val acc: 36.28 (7/66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 44268, 1: 634, 2: 98})\n",
      "Counter({0: 33731, 2: 31744, 1: 4525})\n",
      "Epoch: [52/1000], Loss: 0.004582, Train acc: 96.88, Val acc: 34.0 (8/66)\n",
      "Counter({1: 23778, 2: 20025, 0: 1197})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [53/1000], Loss: 0.003513, Train acc: 100.0, Val acc: 58.16 (9/66)\n",
      "Counter({1: 42413, 0: 1979, 2: 608})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [54/1000], Loss: 0.001526, Train acc: 100.0, Val acc: 39.08 (10/66)\n",
      "Counter({2: 35378, 1: 8380, 0: 1242})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [55/1000], Loss: 0.001129, Train acc: 100.0, Val acc: 43.28 (11/66)\n",
      "Counter({2: 39559, 1: 4814, 0: 627})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [56/1000], Loss: 0.00235, Train acc: 100.0, Val acc: 39.07 (12/66)\n",
      "Counter({2: 39028, 1: 5306, 0: 666})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [57/1000], Loss: 0.002132, Train acc: 100.0, Val acc: 39.55 (13/66)\n",
      "Counter({2: 42238, 1: 2498, 0: 264})\n",
      "Counter({2: 31888, 0: 31664, 1: 6448})\n",
      "Epoch: [58/1000], Loss: 0.004751, Train acc: 99.97, Val acc: 35.98 (14/66)\n",
      "Counter({2: 41276, 1: 3253, 0: 471})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [59/1000], Loss: 0.001963, Train acc: 100.0, Val acc: 37.13 (15/66)\n",
      "Counter({0: 40377, 1: 4442, 2: 181})\n",
      "Counter({2: 31805, 0: 31688, 1: 6507})\n",
      "Epoch: [60/1000], Loss: 0.002811, Train acc: 99.88, Val acc: 36.18 (16/66)\n",
      "Counter({2: 40213, 1: 4319, 0: 468})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [61/1000], Loss: 0.004448, Train acc: 100.0, Val acc: 37.94 (17/66)\n",
      "Counter({1: 43963, 0: 803, 2: 234})\n",
      "Counter({2: 31844, 0: 31688, 1: 6468})\n",
      "Epoch: [62/1000], Loss: 0.00439, Train acc: 99.94, Val acc: 35.64 (18/66)\n",
      "Counter({2: 40739, 1: 3643, 0: 618})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [63/1000], Loss: 0.001935, Train acc: 100.0, Val acc: 37.77 (19/66)\n",
      "Counter({1: 26882, 0: 17385, 2: 733})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [64/1000], Loss: 0.002517, Train acc: 100.0, Val acc: 63.0 (20/66)\n",
      "Counter({2: 38382, 1: 5851, 0: 767})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [65/1000], Loss: 0.001224, Train acc: 100.0, Val acc: 40.27 (21/66)\n",
      "Counter({2: 39517, 1: 4794, 0: 689})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [66/1000], Loss: 0.00228, Train acc: 100.0, Val acc: 39.24 (22/66)\n",
      "Counter({1: 27941, 0: 16621, 2: 438})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [67/1000], Loss: 0.001895, Train acc: 100.0, Val acc: 64.04 (23/66)\n",
      "Counter({0: 42116, 1: 2645, 2: 239})\n",
      "Counter({2: 31848, 0: 31688, 1: 6464})\n",
      "Epoch: [68/1000], Loss: 0.003011, Train acc: 99.94, Val acc: 35.36 (24/66)\n",
      "Counter({2: 37699, 1: 6351, 0: 950})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [69/1000], Loss: 0.001002, Train acc: 100.0, Val acc: 41.36 (25/66)\n",
      "Counter({2: 43006, 1: 1750, 0: 244})\n",
      "Counter({2: 31888, 0: 31651, 1: 6461})\n",
      "Epoch: [70/1000], Loss: 0.004909, Train acc: 99.95, Val acc: 35.31 (26/66)\n",
      "Counter({1: 42109, 0: 2224, 2: 667})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [71/1000], Loss: 0.001705, Train acc: 100.0, Val acc: 39.76 (27/66)\n",
      "Counter({2: 23313, 1: 20257, 0: 1430})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [72/1000], Loss: 0.001277, Train acc: 100.0, Val acc: 51.37 (28/66)\n",
      "Counter({2: 41608, 1: 2994, 0: 398})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [73/1000], Loss: 0.00113, Train acc: 100.0, Val acc: 36.9 (29/66)\n",
      "Counter({2: 41188, 1: 3419, 0: 393})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [74/1000], Loss: 0.001761, Train acc: 100.0, Val acc: 37.17 (30/66)\n",
      "Counter({1: 43149, 0: 1453, 2: 398})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [75/1000], Loss: 0.001386, Train acc: 100.0, Val acc: 37.45 (31/66)\n",
      "Counter({2: 42919, 1: 1873, 0: 208})\n",
      "Counter({2: 31888, 0: 31623, 1: 6489})\n",
      "Epoch: [76/1000], Loss: 0.001784, Train acc: 99.91, Val acc: 35.36 (32/66)\n",
      "Counter({0: 34825, 1: 10038, 2: 137})\n",
      "Counter({2: 31776, 0: 31688, 1: 6536})\n",
      "Epoch: [77/1000], Loss: 0.001386, Train acc: 99.84, Val acc: 39.34 (33/66)\n",
      "Counter({0: 39100, 1: 5592, 2: 308})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [78/1000], Loss: 0.001389, Train acc: 100.0, Val acc: 36.55 (34/66)\n",
      "Counter({1: 23498, 2: 20447, 0: 1055})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [79/1000], Loss: 0.002615, Train acc: 100.0, Val acc: 56.91 (35/66)\n",
      "Counter({2: 37707, 1: 6235, 0: 1058})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [80/1000], Loss: 0.001687, Train acc: 100.0, Val acc: 41.54 (36/66)\n",
      "Counter({2: 43916, 1: 964, 0: 120})\n",
      "Counter({2: 31888, 0: 31555, 1: 6557})\n",
      "Epoch: [81/1000], Loss: 0.002177, Train acc: 99.81, Val acc: 34.36 (37/66)\n",
      "Counter({2: 38986, 1: 5044, 0: 970})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [82/1000], Loss: 0.01235, Train acc: 100.0, Val acc: 40.38 (38/66)\n",
      "Counter({0: 41924, 1: 2846, 2: 230})\n",
      "Counter({2: 31840, 0: 31688, 1: 6472})\n",
      "Epoch: [83/1000], Loss: 0.002185, Train acc: 99.93, Val acc: 35.39 (39/66)\n",
      "Counter({1: 32867, 0: 11924, 2: 209})\n",
      "Counter({2: 31826, 0: 31688, 1: 6486})\n",
      "Epoch: [84/1000], Loss: 0.001517, Train acc: 99.91, Val acc: 48.51 (40/66)\n",
      "Counter({1: 21928, 2: 21803, 0: 1269})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [85/1000], Loss: 0.002552, Train acc: 100.0, Val acc: 54.37 (41/66)\n",
      "Counter({0: 24557, 1: 20132, 2: 311})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [86/1000], Loss: 0.001656, Train acc: 100.0, Val acc: 46.12 (42/66)\n",
      "Counter({2: 42777, 1: 1989, 0: 234})\n",
      "Counter({2: 31888, 0: 31642, 1: 6470})\n",
      "Epoch: [87/1000], Loss: 0.002024, Train acc: 99.93, Val acc: 35.54 (43/66)\n",
      "Counter({2: 42507, 1: 2187, 0: 306})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [88/1000], Loss: 0.001441, Train acc: 100.0, Val acc: 35.82 (44/66)\n",
      "Counter({2: 42717, 1: 2079, 0: 204})\n",
      "Counter({2: 31888, 0: 31619, 1: 6493})\n",
      "Epoch: [89/1000], Loss: 0.004761, Train acc: 99.9, Val acc: 35.28 (45/66)\n",
      "Counter({2: 42068, 1: 2591, 0: 341})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [90/1000], Loss: 0.001581, Train acc: 100.0, Val acc: 36.19 (46/66)\n",
      "Counter({0: 41791, 1: 2957, 2: 252})\n",
      "Counter({2: 31855, 0: 31688, 1: 6457})\n",
      "Epoch: [91/1000], Loss: 0.002976, Train acc: 99.95, Val acc: 35.48 (47/66)\n",
      "Counter({2: 31556, 1: 12644, 0: 800})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [92/1000], Loss: 0.001346, Train acc: 100.0, Val acc: 45.6 (48/66)\n",
      "Counter({1: 26412, 2: 18059, 0: 529})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [93/1000], Loss: 0.001266, Train acc: 100.0, Val acc: 49.4 (49/66)\n",
      "Counter({2: 35293, 1: 8745, 0: 962})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [94/1000], Loss: 0.001269, Train acc: 100.0, Val acc: 43.49 (50/66)\n",
      "Counter({1: 42157, 0: 2117, 2: 726})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [95/1000], Loss: 0.002318, Train acc: 100.0, Val acc: 39.65 (51/66)\n",
      "Counter({2: 37824, 1: 6434, 0: 742})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [96/1000], Loss: 0.002517, Train acc: 100.0, Val acc: 40.6 (52/66)\n",
      "Counter({2: 41972, 1: 2685, 0: 343})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [97/1000], Loss: 0.001988, Train acc: 100.0, Val acc: 36.38 (53/66)\n",
      "Counter({2: 40466, 1: 4000, 0: 534})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [98/1000], Loss: 0.001213, Train acc: 100.0, Val acc: 37.96 (54/66)\n",
      "Counter({2: 31027, 1: 12732, 0: 1241})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [99/1000], Loss: 0.001648, Train acc: 100.0, Val acc: 48.17 (55/66)\n",
      "Counter({2: 37049, 1: 7087, 0: 864})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [100/1000], Loss: 0.001407, Train acc: 100.0, Val acc: 41.75 (56/66)\n",
      "Counter({2: 42776, 1: 1972, 0: 252})\n",
      "Counter({2: 31888, 0: 31655, 1: 6457})\n",
      "Epoch: [101/1000], Loss: 0.0008436, Train acc: 99.95, Val acc: 35.44 (57/66)\n",
      "Counter({2: 44071, 1: 819, 0: 110})\n",
      "Counter({2: 32507, 0: 31548, 1: 5945})\n",
      "Epoch: [102/1000], Loss: 0.002346, Train acc: 98.92, Val acc: 34.18 (58/66)\n",
      "Counter({2: 43184, 1: 1567, 0: 249})\n",
      "Counter({2: 31888, 0: 31654, 1: 6458})\n",
      "Epoch: [103/1000], Loss: 0.007532, Train acc: 99.95, Val acc: 35.15 (59/66)\n",
      "Counter({1: 38070, 0: 6364, 2: 566})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [104/1000], Loss: 0.005773, Train acc: 100.0, Val acc: 48.73 (60/66)\n",
      "Counter({1: 28672, 2: 14969, 0: 1359})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [105/1000], Loss: 0.001345, Train acc: 100.0, Val acc: 55.37 (61/66)\n",
      "Counter({1: 31532, 2: 11767, 0: 1701})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [106/1000], Loss: 0.001306, Train acc: 100.0, Val acc: 52.88 (62/66)\n",
      "Counter({2: 39141, 1: 5294, 0: 565})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [107/1000], Loss: 0.001106, Train acc: 100.0, Val acc: 39.29 (63/66)\n",
      "Counter({2: 41504, 1: 3142, 0: 354})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [108/1000], Loss: 0.001411, Train acc: 100.0, Val acc: 36.63 (64/66)\n",
      "Counter({1: 25655, 0: 18936, 2: 409})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [109/1000], Loss: 0.001028, Train acc: 100.0, Val acc: 58.83 (65/66)\n",
      "Counter({2: 41327, 1: 3196, 0: 477})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [110/1000], Loss: 0.001032, Train acc: 100.0, Val acc: 36.9 (66/66)\n",
      "Counter({2: 41543, 1: 3006, 0: 451})\n",
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "Epoch: [111/1000], Loss: 0.001111, Train acc: 100.0, Val acc: 36.68 (67/66)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 4\n",
    "fc_hid_dim = 32\n",
    "model = fcNet(n_layers, fc_hid_dim).to(DEVICE)\n",
    "# model.linears[0].weight.data = torch.tensor([[-5.,5.],\n",
    "#                                             [1.,-1.],\n",
    "#                                             [5.,-5.]]).to(DEVICE)\n",
    "# model.linears[0].bias.data = torch.tensor([0.,2.,0.]).to(DEVICE)\n",
    "print(model)\n",
    "res = train(model, train_loader_JP, train_loader, 66, learning_rate=3e-4, label=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 31888, 0: 31688, 1: 6424})\n",
      "100.0\n",
      "Counter({0: 13162, 2: 12962, 1: 2576})\n",
      "100.0\n",
      "Counter({1: 21801, 0: 15000, 2: 8199})\n",
      "84.88666666666667\n",
      "Counter({2: 5027, 0: 4972, 1: 1})\n",
      "100.0\n",
      "Counter({1: 150, 0: 150, 2: 150})\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model' + \"-\" + \"\" + '.ckpt'))\n",
    "# model = fcNet(n_layers, fc_hid_dim).to(DEVICE)\n",
    "print(test_model(train_loader_JP, model))\n",
    "print(test_model(val_loader_JP, model))\n",
    "print(test_model(train_loader, model))\n",
    "print(test_model(val_loader, model))\n",
    "print(test_model(train_loader_short, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([train_data_short[0], train_data_short[1]]).T\n",
    "y = train_data_short[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yn811/nlp/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=1, multi_class='multinomial', solver='sag')\n",
    "# clf = LinearSVC(random_state=0, tol=1e-5, max_iter=100000)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "lbfgs + C=1 learns the (almost) correct model.  \n",
    "C=1e30, sag fail, similar to 1 layer NN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array([train_data[0], train_data[1]]).T\n",
    "y_val = train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array([val_data[0], val_data[1]]).T\n",
    "y_val = val_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.366711111111\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X, y), clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87457777777777779"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = clf.predict(X_val)\n",
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62373333333333336"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = 0\n",
    "sum(yh == yi for yh, yi in zip(y_hat, y_val) if yi == lab ) / sum(yi == lab for yi in y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.18961850e-01,   3.18943580e-01],\n",
       "       [  7.21459410e-06,   8.22490433e-06],\n",
       "       [  3.18954636e-01,  -3.18951804e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.82958187e-03,   1.73274617e-03,   9.68357056e-05])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
